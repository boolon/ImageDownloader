{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Build Cards",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "El22NS5rYJg7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqvJ_DM2Tcyv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image\n",
        "from PIL import ImageOps\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as TRS\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khMIgfZ9PYt1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install mtgsdk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agwpqoZwTffn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fonctions pour l'API MTG\n",
        "\n",
        "from mtgsdk import Card\n",
        "from mtgsdk import Set\n",
        "from mtgsdk import Type\n",
        "from mtgsdk import Supertype\n",
        "from mtgsdk import Subtype\n",
        "from mtgsdk import Changelog\n",
        "\n",
        "from random import shuffle\n",
        "\n",
        "\n",
        "import urllib.request"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZztttiQ0jlPM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install praw\n",
        "!pip install wget"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIPDoZtJjlk_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fonctions pour l'API Reddit\n",
        "import re\n",
        "import praw\n",
        "import wget\n",
        "import shutil"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sr0MsgMtSp2g",
        "colab_type": "text"
      },
      "source": [
        "La partie qui suit est consacré au téléchargement et au traitement des cartes. C'est vraiment pas une manière de procéder, mais c'est le code que j'avais utilisé à l'époque, et en toute honnêteté, j'ai pas envie de me consacrer de trop à la partie secondaire. \n",
        "Dans les trucs à amméliorer pour le dataset, il y a se démerder pour que les images soient toujours différentes (ce qui nécessiterait aussi de faire un croismenet avec les images du INE), et il faudrait pouvoir croper un peu mieux les images qui sont pénibles (PW, Schemes...)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuzUoLWNSnn-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BOX = (28, 38, 196, 166)\n",
        "SIZE = (168,128)\n",
        "FACTOR = 0.3\n",
        "\n",
        "# Idéalement, faudrait aller chercher la liste sur le site\n",
        "INE_SUBS = [#\"Angels\",\n",
        "            #\"Immortals\",\n",
        "            #\"Battlefields\",\n",
        "            #\"Cityscapes\",\n",
        "            #\"Mindscapes\",\n",
        "            #\"Pathways\",\n",
        "            #\"Seascapes\",\n",
        "            #\"Skyscapes\",\n",
        "            #\"Starscapes\",\n",
        "            #\"Wastelands\",\n",
        "            #\"Weather\",\n",
        "            #\"Wildlands\",\n",
        "            #\"Worlds\",\n",
        "            #\"Architecture\",\n",
        "            #\"Castles\",\n",
        "            #\"Dwellings\",\n",
        "            #\"Interiors\",\n",
        "            #\"Libraries\",\n",
        "            #\"Beasts\",\n",
        "            #\"Behemoths\",\n",
        "            #\"Carnage\",\n",
        "            #\"Dragons\",\n",
        "            #\"Demons\",\n",
        "            #\"Elementals\",\n",
        "            #\"Horrors\",\n",
        "            #\"Hybrids\",\n",
        "            #\"Leviathans\",\n",
        "            #\"Undead\",\n",
        "            #\"WorldEaters\",\n",
        "            #\"FutureWar\",\n",
        "            #\"Futurism\",\n",
        "            #\"Portals\",\n",
        "            #\"Starships\",\n",
        "            #\"Steampunk\",\n",
        "            #\"Gatherings\",\n",
        "            #\"Autumnscapes\",\n",
        "            #\"Bodyscapes\",\n",
        "            #\"Fogscapes\",\n",
        "            #\"Nightscapes\",\n",
        "            #\"Springscapes\",\n",
        "            #\"Summerscapes\",\n",
        "            #\"Waterscapes\",\n",
        "            #\"Winterscapes\",\n",
        "            #\"Canyons\",\n",
        "            #\"Caves\",\n",
        "            #\"Deserts\",\n",
        "            #\"Forests\",\n",
        "            #\"Glaciers\",\n",
        "            #\"Islands\",\n",
        "            #\"Lakes\",\n",
        "            #\"Mountains\",\n",
        "            #\"Rivers\",\n",
        "            #\"Swamps\",\n",
        "            #\"Trees\",\n",
        "            #\"Volcanoes\",\n",
        "            #\"Waterfalls\",\n",
        "            #\"Asylums\",\n",
        "            #\"Factories\",\n",
        "            #\"Monuments\",\n",
        "            #\"Prisons\",\n",
        "            #\"Ruins\",\n",
        "            #\"Statues\",\n",
        "            #\"Taverns\",\n",
        "            #\"Temples\",\n",
        "            #\"Towers\",\n",
        "            #\"Villages\",\n",
        "            #\"Walls\",\n",
        "            #\"Crawlers\",\n",
        "            \"Dinosaurs\",\n",
        "            \"Spirits\",\n",
        "            \"Unicorns\",\n",
        "            \"Vampires\",\n",
        "            \"Werewolves\",\n",
        "            ]\n",
        "OTHER_SUBS = [\"CelestialBodies\",\n",
        "              ]\n",
        "SUBS = [\"Imaginary{}\".format(ine) for ine in INE_SUBS] +  OTHER_SUBS\n",
        "\n",
        "main_path = os.path.join(os.getcwd(),\"drive\",\"My Drive\", \"CARDS\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WJJLUd-PUX1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def dlsets(sets = None, start_set = None, stop_set = None, path = os.path.join(main_path,\"Cards\")):\n",
        "    '''\n",
        "    Cette fonction télécharge dans le dossier Cards toutes les cartes de tous les sets dans sets à partir du set start_set et jusqu'au set stop_set inclus.\n",
        "    '''\n",
        "    if sets == None:\n",
        "        sets = Set.all()\n",
        "    if start_set == None:\n",
        "        dl = True\n",
        "    else:\n",
        "        dl = False\n",
        "    try:\n",
        "        os.mkdir(os.path.join(main_path,\"Cards\"))\n",
        "    except:\n",
        "        pass\n",
        " \n",
        "    for set in sets:\n",
        "        if set.name == start_set:\n",
        "            dl = True\n",
        "        if dl:\n",
        "            dlset(set, path)\n",
        "        else:\n",
        "            print(\"Skipping {}\".format(set.name))\n",
        "        if set.name == stop_set:\n",
        "            dl = False\n",
        "\n",
        "def dlone(set):\n",
        "    dlsets(start_set = set, stop_set = set)\n",
        "\n",
        "def dlset(set, path):\n",
        "    print(\"Téléchargement du set : \" + set.name)\n",
        "    cards = Card.where(set=set.code).all()\n",
        "    for card in cards:\n",
        "        if card.image_url != None:\n",
        "            dlcard(card, path)\n",
        "\n",
        "def dlcard(card, path):\n",
        "    print(\"Téléchargement de la carte : \" + card.name + \" (\" + str(card.multiverse_id) + \")\")\n",
        "    if card.image_url == None:\n",
        "        print(\"Erreur dans le téléchargement, la carte n'a pas d'illustration.\")\n",
        "        return\n",
        "    try:\n",
        "        urllib.request.urlretrieve(card.image_url, os.path.join(path, str(card.multiverse_id)))\n",
        "    except:\n",
        "        print(\"Attention : une carte n'a pas été téléchargée avec l'ID {}\".format(id))\n",
        "\n",
        "def crop_cards(selected_cards = None, start_card = None):\n",
        "    try:\n",
        "        os.makedirs(os.path.join(main_path,\"Cards_croped\"))\n",
        "    except:\n",
        "        print(\"Failed to create file for croped cards, maybe there is already one\")\n",
        "        pass\n",
        "    cards = os.listdir(os.path.join(main_path,\"Cards\"))\n",
        "    if start_card != None:\n",
        "        cards = cards[cards.index(start_card)+1:]\n",
        "    for card in cards:\n",
        "        if selected_cards == None or card in selected_cards:\n",
        "            crop_one(card)\n",
        "\n",
        "def resize_cards(selected_cards = None, start_card = None):\n",
        "    try:\n",
        "        os.mkdir(os.path.join(main_path,\"Cards_resized\"))\n",
        "    except:\n",
        "        pass\n",
        "    cards = os.listdir(os.path.join(main_path,\"Cards_croped\"))\n",
        "    if start_card != None:\n",
        "        cards = cards[cards.index(start_card)+1:]\n",
        "    for card in cards:\n",
        "        if selected_cards == None or card in selected_cards:\n",
        "            resize_one(card)\n",
        "\n",
        "def resize_one(card,path_to_crops = os.path.join(main_path,\"Cards_croped\"), path_to_resize = os.path.join(main_path,\"Cards_resized\")):\n",
        "    print(\"Resize de la carte :\" + str(card))\n",
        "    try:\n",
        "        picture = Image.open(os.path.join(path_to_crops, card))\n",
        "        resize = picture.resize(SIZE)\n",
        "    except:\n",
        "        pass\n",
        "    resize.save(os.path.join(path_to_resize,card), format = picture.format)\n",
        "\n",
        "def crop_one(card, path_to_crops = os.path.join(main_path,\"Cards_croped\"), path_to_cards = os.path.join(main_path,\"Cards\")):\n",
        "    print(\"Crop de la carte : \" + str(card))\n",
        "    try:\n",
        "        picture = Image.open(os.path.join(path_to_cards, card))\n",
        "        crop = picture.crop(BOX)\n",
        "    except OSError:\n",
        "        print(\"OSError, peut-être la carte suivante est absente : \" + str(card))\n",
        "        card2 = Card.find(card)\n",
        "        dlcard(card2, path_to_cards)\n",
        "        picture = Image.open(os.path.join(path_to_cards, card))\n",
        "        crop = picture.crop(BOX)\n",
        "    crop.save(os.path.join(path_to_crops, card), format = picture.format)\n",
        "\n",
        "def label_cards(path_to_cards = os.path.join(main_path,\"Cards_resized\"), path_to_labeled = os.path.join(main_path,\"Cards_labeled\")):\n",
        "    try:\n",
        "        os.makedirs(path_to_labeled)\n",
        "    except:\n",
        "        pass\n",
        "    cards = os.listdir(path_to_cards)\n",
        "    shuffle(cards)\n",
        "    for card in cards:\n",
        "        label_one(card, path_to_cards = path_to_cards, path_to_labeled = path_to_labeled)\n",
        "\n",
        "def label_one(card, path_to_cards, path_to_labeled):\n",
        "    print(\"Labeling : \", card)\n",
        "    try:\n",
        "        id = int(card)\n",
        "    except:\n",
        "        print(\"Id incompatible :\", card)\n",
        "        return\n",
        "    #picture = Image.open(os.path.join(path_to_cards, card))\n",
        "    labeled = os.listdir(path_to_labeled)\n",
        "    for label in labeled:\n",
        "        if label[:len(card)] == card and label[len(card)] == \"C\":\n",
        "            color = label[label.find(\"C\"):]\n",
        "            print(\"Carte déjà présente avec l'identité couleur : \", color)\n",
        "            #picture.save(os.path.join(path_to_labeled, card + color), format = picture.format)\n",
        "            return\n",
        "    j = 0\n",
        "    card_gatherer = Card.find(id)\n",
        "    while 1:\n",
        "        try:\n",
        "            card_gatherer = Card.find(id)\n",
        "        except:\n",
        "            j += 1\n",
        "            if j==1:\n",
        "                print(\"Échec pour étiqueter la carte, elle ne sera pas ajouté au set de données.\")\n",
        "                return\n",
        "    color_identity = card_gatherer.color_identity\n",
        "    if color_identity == None:\n",
        "        color = \"C\"\n",
        "    else:\n",
        "        color = \"C\"+\"\".join(color_identity)\n",
        "    print(\"Color identityt is {}\".format(color_identity))\n",
        "    open(os.path.join(path_to_labeled,card + color), 'a').close()\n",
        "\n",
        "\n",
        "def fetch_repartition(path_to_cards = os.path.join(main_path,\"Cards_labeled\")):\n",
        "    cards = os.listdir(path_to_cards)\n",
        "    result = dict()\n",
        "    for card in cards:\n",
        "        color = card[card.find(\"C\"):]\n",
        "        color_index = 1\n",
        "        colors = [\"W\",\"U\",\"B\",\"R\",\"G\"]\n",
        "        prime = [2,3,5,7,11]\n",
        "        for i in range(5):\n",
        "            if colors[i] in color:\n",
        "                color_index *=prime[i]\n",
        "        color = \"\"\n",
        "\n",
        "        for i in range(5):\n",
        "            if color_index%prime[i] == 0:\n",
        "                color += colors[i]\n",
        "        try:\n",
        "            result[color]+=1\n",
        "        except:\n",
        "            result[color] =1\n",
        "    return result\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNaBU__SP0F2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cette fonction n'a pas de manière de faire de récupération de ce qui a déjà \n",
        "# été téléchargé, mais elle peut reprendre un téléchargement en cours en \n",
        "# spécifiant le nom du set de départ\n",
        "\n",
        "dlsets()\n",
        "\n",
        "crop_cards()\n",
        "\n",
        "resize_cards()\n",
        "\n",
        "\n",
        "# La fonction suivante gère assez mal les images qui ne peuvent pas être \n",
        "# étiquettée : elle essaye une ou deux fois et après dit que l'image ne devait \n",
        "# pas correspondre à une carte. L'exécution prend du temps même si tout a déjà \n",
        "# été fait, et ne fournit même pas l'assurance d'étiqueter tout ce qui est \n",
        "# possible.\n",
        "\n",
        "label_cards()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9q9Wbidijnl",
        "colab_type": "text"
      },
      "source": [
        "Cette partie est consacrée à télécharger les fichiers du INE et de les transformer et les découper en conséquences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBZu3z0t8FA9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkWords = ['i.imgur.com',  'jpg', 'png', 'gif', 'gfycat.com', 'webm',]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEUQ_EUTQxi_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def download_INE(subs = SUBS, path_to_rip = \"rips\"):\n",
        "    try:\n",
        "        os.makedirs(path_to_rip)\n",
        "    except:\n",
        "        pass\n",
        "    with open(os.path.join(main_path, \"reddit.id\"), \"r\") as file_info_reddit:\n",
        "        info_reddit = file_info_reddit.read().split(\"\\n\")\n",
        "        r = praw.Reddit(client_id = info_reddit[0], client_secret= info_reddit[1], user_agent = \"INE dl\")\n",
        "    for sub in subs:\n",
        "        print(\"Téléchargement des fichiers du Sub {}\".format(sub))\n",
        "        download_sub(r, sub, path_to_rip = path_to_rip)\n",
        "        convert_and_resize(path_to_rip = path_to_rip)\n",
        "        shutil.rmtree(os.path.join(path_to_rip, sub))\n",
        "\n",
        "\n",
        "def download_sub(r, sub, path_to_rip =  \"rips\"):\n",
        "    path_to_sub_file = os.path.join(path_to_rip, sub)\n",
        "    try:\n",
        "        os.makedirs(path_to_sub_file)\n",
        "    except:\n",
        "        pass\n",
        "    subreddit = r.subreddit(sub)\n",
        "    for submission in subreddit.top(limit = 1000):\n",
        "        url_text = submission.url\n",
        "        has_domain = any(string in url_text for string in checkWords)\n",
        "        print('[LOG] Getting url:  ' + url_text)\n",
        "        if has_domain and submission.score >0 and submission.upvote_ratio > 0.5:\n",
        "            try:\n",
        "                wget.download(url_text, os.path.join(path_to_rip,sub ,sub + str(time.time())[-8:-3] + url_text[-4:]))\n",
        "                #print('[LOG] Done Getting ' + url_text)\n",
        "            except:\n",
        "                #print(\"Can't download from location : {}\".format(url_text))\n",
        "                try:\n",
        "                    wget.download(submission.preview[\"images\"][0][\"source\"][\"url\"],os.path.join(path_to_rip,sub ,sub + str(time.time())[-8:-3] + url_text[-4:]))\n",
        "                    #print('[LOG] Done Getting from preview :' + submission.preview[\"images\"][0][\"source\"][\"url\"])\n",
        "                except:\n",
        "                    print(\"Can't download from reddit preview or from direct source: {}\".format(str(url_text)))\n",
        "\n",
        "def convert_and_resize(path_to_rip = \"rips\", path_to_resize = os.path.join(main_path, \"rips_resized\")):\n",
        "    try:\n",
        "        os.makedirs(path_to_resize)\n",
        "    except:\n",
        "        pass\n",
        "    files = os.listdir(path_to_rip)\n",
        "    for file in files:\n",
        "        print(\"Processing : \", file)\n",
        "        try:\n",
        "            pictures = os.listdir(os.path.join(path_to_rip,file))\n",
        "        except os.NotADirectory:\n",
        "            print(\"{} is not a valid directory.\".format(file))\n",
        "        for picture in pictures:\n",
        "            if picture[-4:] in [\".png\",\".jpg\"]:\n",
        "                convert_and_resize_one(os.path.join(path_to_rip,file, picture), path_to_resize = path_to_resize, name = picture)\n",
        "\n",
        "def convert_and_resize_one(path_to_picture, path_to_resize = os.path.join(main_path, \"rips_resized\"), name = \"test.png\"):\n",
        "    print(\"Converting :\", path_to_picture)\n",
        "    try:\n",
        "        picture = Image.open(path_to_picture)\n",
        "    except:\n",
        "        print(\"Error : cant open file :\", path_to_picture)\n",
        "        return\n",
        "    already_resized = os.listdir(path_to_resize)\n",
        "    if picture.size[0]/picture.size[1] > SIZE[0]/SIZE[1]:\n",
        "        factor = SIZE[1]/picture.size[1]\n",
        "        picture = picture.resize((int(picture.size[0] * factor), SIZE[1]))\n",
        "        picture = picture.crop((picture.size[0]//2 - SIZE[0]//2,0, picture.size[0]//2 + SIZE[0]//2 + int(SIZE[0]%2 ==1),SIZE[1]))\n",
        "    else:\n",
        "        factor = SIZE[0]/picture.size[0]\n",
        "        picture = picture.resize((SIZE[0], int(picture.size[1] * factor)))\n",
        "        if picture.size[1] * FACTOR <  SIZE[1]//2:\n",
        "            picture = picture.crop((0,0,SIZE[0],SIZE[1]))\n",
        "        else:\n",
        "            picture = picture.crop((0,int(picture.size[1] * FACTOR) - SIZE[1]//2,SIZE[0],int(picture.size[1]* FACTOR) + SIZE[1]//2 + int(SIZE[1]%2 ==1)))\n",
        "    assert picture.size == SIZE\n",
        "    try:\n",
        "        picture.save(os.path.normpath(os.path.join(path_to_resize,name)), format = picture.format)\n",
        "    except:\n",
        "        print(\"Error : cant save file:\", path_to_picture)\n",
        "        return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ba064kvajRbt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cette fonction est principalement récupérée depuis :\n",
        "# https://github.com/IeuanG/mxtm/blob/master/main.py\n",
        "download_INE(subs = SUBS)\n",
        "\n",
        "\n",
        "#\n",
        "#convert_and_resize()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iQpZsbCGB7S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(os.listdir(os.path.join(main_path, \"rips_resized\")))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfU0bz22PIxX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(os.listdir(os.path.join(main_path, \"Cards_resized\")))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76YHc_LOQVZ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jh_oEuagDT5W",
        "colab_type": "text"
      },
      "source": [
        "Un petit paquet de foncitons utilitaires:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2mMgd3XDXUw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "use_gpu = torch.cuda.is_available()\n",
        "if use_gpu:\n",
        "    print(\"GPU utilisable\")\n",
        "    \n",
        "def gpu(tensor, gpu=use_gpu):\n",
        "    if gpu:\n",
        "        return tensor.cuda()\n",
        "    else:\n",
        "        return tensor\n",
        "     \n",
        "def show(img):\n",
        "    npimg = img.numpy()\n",
        "    plt.figure(figsize = (20,20))\n",
        "    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n",
        "    \n",
        "def sigma(x):\n",
        "    return torch.clamp(x,0,1)\n",
        "\n",
        "def onehot_from_label(x, label_dim = 10):\n",
        "    label_onehot = gpu(torch.FloatTensor(x.size()[0], label_dim))\n",
        "    label_onehot.zero_()\n",
        "    label_onehot.scatter_(1,x.long().view(-1,1), 1)\n",
        "    return label_onehot\n",
        "\n",
        "def random_label(batch_size = batch_size, label_dim = 5, multi_label = False):\n",
        "    if multi_label:\n",
        "        pass\n",
        "    else:\n",
        "        return onehot_from_label(gpu(torch.randint(high = label_dim, size = (batch_size,))))\n",
        "\n",
        "def test_label(batch_size = batch_size, label_dim = 5):\n",
        "    return onehot_from_label(gpu(torch.Tensor([i%label_dim for i in range(batch_size)])))\n",
        "\n",
        "def index_to_colors(l):\n",
        "    result = \"\"\n",
        "    for i in range(5):\n",
        "        if l[i]>0.5:\n",
        "            result += COLORS[i]\n",
        "        elif l[i]>0.1:\n",
        "            result += COLORS[i].lower()\n",
        "    return result\n",
        "\n",
        "\n",
        "\n",
        "def show_loss(loss_G_list, loss_D_list, loss_C_list = None):\n",
        "    plt.figure()\n",
        "    plt.plot(list(range(len(loss_G_list))),loss_G_list, label = \"generator\")\n",
        "    plt.show()\n",
        "    plt.figure()\n",
        "    plt.plot(list(range(len(loss_D_list))),loss_D_list, label = \"discriminator\")\n",
        "    plt.show()\n",
        "    if loss_C_list != None:\n",
        "        plt.figure()\n",
        "        plt.plot(list(range(len(loss_C_list))),loss_C_list, label = \"classifier\")\n",
        "        plt.show()\n",
        "        \n",
        "def test_D(net_C, batch,n = 5):\n",
        "    out = batch.view(-1, 3, 128, 168)[:n]\n",
        "    out_grid = torchvision.utils.make_grid(out, nrow = 5).cpu()\n",
        "    result = net_C(batch)\n",
        "    for i in range(min(n,len(result))):\n",
        "        print(i, index_to_colors(result[i]))\n",
        "    show(sigma(out_grid))\n",
        "    \n",
        "    \n",
        "def show_exemple(net_G, size1 = 28, size2 = 28, n_label = 5, n_row = 5, channel = 1, max_n = 20, test_mode = False):\n",
        "    if test_mode:\n",
        "        n_row = n_row//(T+1)\n",
        "    if use_C:\n",
        "        label = test_label(label_dim = n_label)\n",
        "        with torch.no_grad():\n",
        "            out = net_G(label = label, test_mode = test_mode).view(-1, channel, size1, size2*(T+1))[:max_n]\n",
        "        out_grid = torchvision.utils.make_grid(out, nrow = n_row).cpu()\n",
        "    else:\n",
        "        with torch.no_grad():\n",
        "            out = net_G(test_mode = test_mode).view(-1, channel, size1 , size2 * (T+1))[:max_n]\n",
        "        out_grid = torchvision.utils.make_grid(out, nrow = n_row).cpu()\n",
        "\n",
        "    show(sigma(out_grid))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCh_CSDkC3-p",
        "colab_type": "text"
      },
      "source": [
        "Maintenant, il s'agit de faire les datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9-bkGEJRoHy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class UnlabeledData(torch.utils.data.Dataset):\n",
        "    def __init__(self, path_to_pictures):\n",
        "        self.cards = os.listdir(path_to_pictures)\n",
        "        self.path_to_pictures = path_to_pictures\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        if index > len(self.cards):\n",
        "            mirror = True\n",
        "        else:\n",
        "            mirror = False\n",
        "        img = Image.open(os.path.join(self.path_to_pictures,self.cards[index - int(mirror)*len(self.cards)]))\n",
        "        if mirror:\n",
        "            img2 = ImageOps.mirror(img)\n",
        "        else:\n",
        "            img2 = img\n",
        "        img2 = img2.convert(\"RGB\")\n",
        "        img.close()\n",
        "        img = np.asarray(img2, dtype = \"float\").transpose(-1, 0, 1)\n",
        "        img = torch.from_numpy(np.asarray(img, dtype = \"float\")).float()\n",
        "        return img/255\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.cards)\n",
        "\n",
        "class LabeledData(torch.utils.data.Dataset):\n",
        "    def __init__(self, path_to_pictures):\n",
        "        self.cards = os.listdir(path_to_pictures)\n",
        "        self.path_to_pictures = path_to_pictures\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        if index > len(self.cards):\n",
        "            mirror = True\n",
        "        else:\n",
        "            mirror = False\n",
        "        card = self.cards[index- int(mirror)*len(self.cards)]\n",
        "        img = Image.open(os.path.join(self.path_to_pictures,card))\n",
        "        if mirror:\n",
        "            img2 = ImageOps.mirror(img)\n",
        "        else:\n",
        "            img2 = img\n",
        "        img2 = img2.convert(\"RGB\")\n",
        "        img.close()\n",
        "        img = np.asarray(img2,dtype = \"float\").transpose(-1, 0, 1)\n",
        "        img = torch.from_numpy(np.asarray(img)).float()\n",
        "        label = torch.zeros(5)\n",
        "        color = [\"W\",\"U\",\"B\",\"R\",\"G\"]\n",
        "        for i in range(len(color)):\n",
        "            if color[i] in card:\n",
        "                label[i] = 1.\n",
        "        return img/255,label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.cards)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVDLmyd4EYiU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unlabeled_set = UnlabeledData(os.path.join(main_path, \"rips_resized\"))\n",
        "unlabeled_loader = torch.utils.data.DataLoader(unlabeled_set, batch_size = batch_size, shuffle = True, drop_last = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6FJLrnJoF1T",
        "colab_type": "text"
      },
      "source": [
        "On passe maintenant au duo generateur / discrimateur.\n",
        "On veut utiliser le papier suivant : https://arxiv.org/pdf/1912.04958.pdf."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZt0j6t2oFYI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVB1jJWJQRfW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}